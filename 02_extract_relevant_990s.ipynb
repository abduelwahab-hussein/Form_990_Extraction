{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a31f4ad-b17a-4de8-ab1d-ab2dbe599c0a",
   "metadata": {},
   "source": [
    "# Extract Relevant Form 990s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f008925-9eb5-4ad3-a788-c06ea97708bf",
   "metadata": {},
   "source": [
    "## Goal of this script: \n",
    "\n",
    "The goal of this script is to store the Form 990s of the NPOs you are interested in a specific folder for later extraction and analysis. The previous script outputted the Entity Identification Numbers (EINs) of the NPOs we are interested in into a .txt file, which we will use as an input for this code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284ecb60-8485-48ab-b748-02e052f7ce3e",
   "metadata": {},
   "source": [
    "## Step 1: Download XML files\n",
    "\n",
    "The IRS used to use Amazon Web Services (AWS) to store the Form 990s of NPOs. However, now, the IRS directly links all Form 990 XML forms by year, from 2018-2024, on its website: https://www.irs.gov/charities-non-profits/form-990-series-downloads\n",
    "\n",
    "Unfortunately, you have to (from my knowledge) download 990 data for ALL NPOs for the years you are interested in, and then extract the specific Form 990s are interested in. This is because the IRS does not have any tools to identify NPO Form 990s you are interested in online, and the IRS does not let you download select Form 990s. **Note that the Form 990 data amounts to around 20 GB per year, so across 2018-2023, this amount to around 120 GB.**\n",
    "\n",
    "So, without further adue, to downlaod the XML files,:\n",
    "\n",
    "- Go to: https://www.irs.gov/charities-non-profits/form-990-series-downloads, and download the years you are interested in.\n",
    "- Once downloaded, unzip the data to a folder of your choosing using extraction software like 7-Zip. I have found unzipping using your Windows local unzipping function takes an much longer time than using 7-Zip.\n",
    "\n",
    "\n",
    "2019-16\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16063287-9f75-4076-a1fa-fb8b6e9593e8",
   "metadata": {},
   "source": [
    "## Step 2: Extract your NPO Form 990s\n",
    "\n",
    "- Lastly, run the below code to extract the NPO Form 990s you care about. The only part of the code you need to change and replace with your own directories are  **_nonprofits_directory_**, **_source_directory_**, and **_target_eins_file_**\n",
    "- The code simply checks each Form 990 XML File for the filer EIN and sees if it matches any of the EINs you care about.\n",
    "- The detect_encoding function is important because it seems that there are various encodings a file can take, such as UTF-8 vs. something else. This is important when we want to actually read the file, because sometimes the XML files won't open unless you specify the encoding of the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbeafcc6-9010-4102-ba54-2b1a1cfda72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import chardet\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "# Path to the directory for storing selected nonprofits' files\n",
    "nonprofits_directory = \"990_Research\\\\important_990s\\\\nonprofits_directory\"\n",
    "\n",
    "# Path to the directory containing the files to be processed\n",
    "source_directory = \"990_Research\\\\form_990s\\\\2023\"\n",
    "\n",
    "# Path to the file containing the target EINs\n",
    "target_eins_file = \"990_Research\\\\nonprofit_data\\\\EINs.txt\"\n",
    "\n",
    "# Load target EINs from a file and add <EIN> tags\n",
    "def load_target_eins(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        target_eins = {line.strip() for line in file}\n",
    "    return target_eins\n",
    "\n",
    "# Function to detect the encoding of a file using chardet library\n",
    "def detect_encoding(file_path):\n",
    "    # Open the file in binary mode\n",
    "    with open(file_path, 'rb') as f:\n",
    "        # Read the entire file content\n",
    "        raw_data = f.read()\n",
    "        # Detect the encoding\n",
    "        result = chardet.detect(raw_data)\n",
    "        # Extract the detected encoding\n",
    "        encoding = result['encoding']\n",
    "        # Return the detected encoding\n",
    "        return encoding\n",
    "\n",
    "# Function to process a single file\n",
    "def process_file(file_path):\n",
    "    try:\n",
    "        # Detect the file's encoding\n",
    "        encoding = detect_encoding(file_path)\n",
    "        # Open the file with the detected encoding\n",
    "        with open(file_path, 'r', encoding=encoding) as file:\n",
    "            contents = file.read()\n",
    "            # Use BeautifulSoup to parse the XML content\n",
    "            soup = BeautifulSoup(contents, 'xml')\n",
    "            # Find the <Filer> section\n",
    "            EIN = soup.find('Filer').find('EIN').text\n",
    "            if EIN in target_EINs:\n",
    "                # Copy the file if target EIN is found\n",
    "                shutil.copy(file_path, nonprofits_directory)\n",
    "                # Remove the EIN from the set\n",
    "                target_EINs.discard(EIN)\n",
    "                # Return the path if EIN found\n",
    "                return file_path\n",
    "    except Exception as e:\n",
    "        # Return an error message if an exception occurs\n",
    "        return f\"Error processing {file_path}: {e}\"\n",
    "\n",
    "    # Return None if no target EIN is found\n",
    "    return None\n",
    "\n",
    "# Generator function to get all file paths in the directory\n",
    "def get_all_files(directory):\n",
    "    # Walk through directory\n",
    "    for root, _, files in os.walk(directory):\n",
    "        # Iterate over each file\n",
    "        for filename in files:\n",
    "            # Yield the full file path\n",
    "            yield os.path.join(root, filename)\n",
    "\n",
    "# Load the target EINs into a set\n",
    "target_EINs = load_target_eins(target_eins_file)\n",
    "\n",
    "# Gather all file paths into a list\n",
    "all_files = list(get_all_files(source_directory))\n",
    "\n",
    "# Process each file\n",
    "for file_path in all_files:\n",
    "    result = process_file(file_path)\n",
    "    if result:\n",
    "        print(f\"Processed: {result}\")\n",
    "\n",
    "print(\"done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b78587f-a85b-4931-b1e8-abf7f735945f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8101ae3c-bad9-484d-99c9-44d3dc6ec8be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
